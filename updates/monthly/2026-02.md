---
title: "February 2026 Research Summary"
date: 2026-02-01
tags:
  - monthly-summary
  - ai-pm-research
---

# February 2026 Research Summary

Agent infrastructure crossed from experimental to production-ready this month. Vercel shipped 69,000+ skills and video generation through AI Gateway, LangChain proved memory systems make agents learn from usage, and GitHub embedded agents directly into CI/CD pipelines. The shift isn't about better models—it's about the infrastructure layer that makes agents actually work at scale.

But working at scale requires rethinking workflows entirely. Teresa showed how context degrades predictably in long conversations, forcing product design around architectural constraints. Lenny documented PMs using MCPs to automate meeting prep and CRM updates—moving AI from "chat interface" to "workflow automation." The emerging pattern: agents need persistent memory, multimodal capabilities, and access to organizational systems to replace manual work, not just assist with it.

## What Matters

- **Agent memory systems change the product model fundamentally.** LangChain's Agent Builder remembers corrections, preferences, and successful patterns across sessions—making agents that improve through usage rather than staying stateless. Perplexity's agentic memory doesn't just recall facts; it actively shapes research strategy based on your history. The shift: agents becoming learning assets with switching costs, not utilities you can swap easily.

- **Infrastructure matters more than model capability for production agents.** LangChain improved Terminal Bench performance from Top 30 to Top 5 without changing models—just optimizing the harness through self-verification loops and trace-based debugging. Vercel's 69,000 agent skills marketplace means teams orchestrate existing capabilities instead of building custom tools. GitHub's Agentic Workflows automate issue triage and PR reviews directly in CI/CD. The pattern: better agent performance comes from infrastructure (sandboxes, orchestration, observability), not waiting for GPT-6.

- **"Vibe coding" emerged as a real job category, but with clear boundaries.** StrongDM's 3-person AI team ships production features by describing outcomes to Claude Code and v0—no traditional coding required. Lenny's survey shows PMs use AI for prototypes and internal tools, not customer-facing features. The limitation: works for isolated features with strong boundaries and quality gates, not tightly coupled systems. Linear's CEO argues most features don't need agent complexity—well-crafted prompts deliver 90% of value with 10% of overhead.

## Essential Resources

1. **LangChain** — [How Memory Transforms Agents](https://blog.langchain.com/how-to-use-memory-in-agent-builder/) — Shows agents learning from corrections across sessions, not just within conversations—making them stickier products with switching costs.

2. **Lenny Rachitsky** — [Validating AI Analysis You Can Trust](https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually) — Four practices (sanity checks, code review, cross-validation, test cases) that make AI-generated data analysis reliable for decisions.

3. **Teresa Torres** — [Context Rot and Session Design](https://www.producttalk.org/context-rot/) — Explains why AI quality degrades at 50-70% context capacity—forcing product decisions around architectural constraints, not user preference.

---

*21 daily updates tracked 85 items this month. [View all February updates](/?from=2026-02-01&to=2026-02-28)*
---

*21 daily updates tracked 21 items this month. [View all February updates](/?from=2026-02-01&to=2026-02-28)*