---
title: "February 2026 Research Summary"
date: 2026-02-01
tags:
  - monthly-summary
  - ai-pm-research
---

# February 2026 Research Summary

February marked a shift from "what can AI do?" to "who can do it and how?" Lenny's community survey revealed most PMs use AI tools for research and prototypes—not production deployment—despite tools promising end-to-end feature shipping. Meanwhile, a visually impaired engineer demonstrated Claude Code enabling workflows previously impossible without sighted assistance, and StrongDM's "vibe coding" team shipped production features without traditional coding skills.

The infrastructure layer matured significantly. GitHub embedded agents directly into CI/CD pipelines for automated repository maintenance. LangChain defended frameworks as essential production infrastructure despite model improvements. Microsoft's enterprise survey showed 80% of Fortune 500 companies deploying active agents—but identified observability, governance, and security gaps blocking wider adoption.

## What Matters

- **AI coding tools expand who can code, but adoption lags capability.** Lenny's survey showed PMs use AI for prototypes and research—avoiding production deployment even with frameworks available. Yet a visually impaired engineer ships features independently using Claude Code's conversational interface, and StrongDM pays "vibe coders" to build production software by describing intent rather than writing implementation. The gap isn't technical—it's trust. PMs hesitate to ship AI-generated code not because tools lack capability, but because they can't reliably assess quality without engineering review.

- **Agent infrastructure requires orchestration layers, not just better models.** LangChain argued frameworks remain essential despite model improvements—handling state management, observability, and safety that models don't provide. GitHub's Agentic Workflows embedded agents into CI/CD for automated issue triage and documentation updates. Perplexity's Council Mode orchestrated multiple specialized models instead of relying on one general model. The pattern: production agents need surrounding infrastructure for orchestration, monitoring, and error handling—better reasoning alone isn't sufficient.

- **Context management shapes AI product design more than capability.** Teresa documented "context rot"—quality degrading predictably as conversations lengthen—explaining why products force session resets or spawn subagents. LangChain's sandbox patterns revealed architectural choices (tool-based vs. environment-based) that determine agent capabilities and failure modes. Vercel launched Geist Pixel, a design system specifically for AI-native interfaces that handle streaming, uncertainty, and iterative refinement. The constraint: context windows and architectural boundaries dictate product decisions as much as model performance.

## Essential Resources

1. **Lenny Rachitsky** — [How a Visually Impaired Engineer Ships Features with Claude Code](https://www.lennysnewsletter.com/p/how-this-visually-impaired-engineer) — Demonstrates how AI coding tools create accessibility breakthroughs by eliminating visual dependencies in development workflows.

2. **LangChain** — [The Two Patterns by Which Agents Connect Sandboxes](https://blog.langchain.com/the-two-patterns-by-which-agents-connect-sandboxes/) — Documents fundamental architectural choices (tool-based vs. environment-based) that determine agent capabilities and security models.

3. **Teresa Torres** — [Context Rot: Why AI Gets Worse the Longer You Chat](https://www.producttalk.org/context-rot/) — Explains quality degradation in long conversations as architectural constraint, not bug—revealing why products implement session boundaries and subagent patterns.

---

*16 daily updates tracked 19 items this month. [View all February updates](/?from=2026-02-01&to=2026-02-29)*
---

*16 daily updates tracked 16 items this month. [View all February updates](/?from=2026-02-01&to=2026-02-28)*