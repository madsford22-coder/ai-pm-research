---
title: "February 2026 Research Summary"
date: 2026-02-01
tags:
  - monthly-summary
  - ai-pm-research
---

# February 2026 Research Summary

February marked a shift from "can AI do this?" to "can AI do this fast enough to matter?" Perplexity doubled Deep Research speed because latency—not capability—blocks adoption. Teresa Torres revealed how context windows degrade predictably, forcing products to choose between long conversations and quality maintenance. The pattern: agents cross from demos to daily workflows when they solve architectural constraints, not just add features.

For PMs, the month delivered practical frameworks: Lenny's deliberate practice guide for building AI product sense, Dr. Becky's leadership principles that apply equally to teams and toddlers, and concrete examples of MCPs automating meeting prep without manual prompting. The through-line: AI product work requires new skills, but those skills are trainable through specific practices.

## What Matters

- **Speed as the adoption threshold, not capability.** Perplexity's Advanced Deep Research drops latency from minutes to sub-minute while maintaining quality. The insight: users tolerate 90 seconds for complex research but switch to manual work at 5 minutes. Agents don't need to be smarter—they need to be fast enough to substitute manual workflows. For PMs building agents, measure user tolerance for latency, then architect to stay under that threshold.

- **Context rot shapes product architecture, not just UX.** Teresa Torres documented how AI responses degrade as conversations lengthen—quality drops at 50-70% of context capacity, not at the limit. This explains why ChatGPT forces resets and Claude introduces Projects. It's not preference; it's managing an architectural constraint. Products must choose: long sessions that preserve continuity but risk degradation, or frequent resets that maintain quality but lose thread. The question for conversational AI products isn't "should we handle long conversations?" but "how do we structure sessions to prevent quality collapse?"

- **AI product sense as deliberate practice, not osmosis.** Lenny's framework identifies five trainable skills: active experimentation (use products daily and break them), pattern recognition (compare solutions across domains), understanding one layer deeper (know tokenization and context windows), rapid shipping (volume builds judgment), and studying failures (yours and others'). This addresses the PM skill gap: how to improve when the field changes weekly. The answer isn't reading more—it's practicing specific patterns until they become intuition.

## Essential Resources

1. **Lenny Rachitsky** — [How to Build AI Product Sense](https://www.lennysnewsletter.com/p/how-to-build-ai-product-sense) — Five concrete practices for developing AI judgment through deliberate experimentation and pattern recognition.

2. **Teresa Torres** — [Context Rot: Why AI Gets Worse the Longer You Chat](https://www.producttalk.org/context-rot/) — Technical analysis of how attention mechanisms degrade with conversation length and what it means for product design.

3. **Lenny Rachitsky** — [How This PM Uses MCPs to Automate Meeting Prep & CRM Updates](https://www.lennysnewsletter.com/p/how-this-pm-uses-mcps-to-automate) — Walkthrough of Model Context Protocol servers handling autonomous workflow updates without manual prompting.

---

*5 daily updates tracked this month. [View all February updates](/?from=2026-02-01&to=2026-02-28)*
---

*5 daily updates tracked 5 items this month. [View all February updates](/?from=2026-02-01&to=2026-02-28)*