---
title: "Agent Memory Systems & Video Generation Through AI Gateway"
date: 2026-02-22
tags:
  - daily-update
  - ai-pm-research
---

## One-Line Summary

LangChain reveals how Agent Builder's memory system works architecturally—storing structured feedback that shapes future agent behavior—while Vercel ships 69,000+ agent skills and video generation infrastructure, showing memory and multimodal workflows becoming production requirements.

---

## Items

### LangChain - How We Built Agent Builder's Memory System
**Source:** https://blog.langchain.com/how-we-built-agent-builders-memory-system/
**Credibility:** High (detailed technical architecture from first-party implementation)

**What happened:** LangChain published technical details on Agent Builder's memory system—revealing how they store and apply user feedback to make agents improve through usage, not just better prompts.

**Key architectural patterns:**

**How memory is stored and structured:**
- **Feedback as structured data**: User corrections stored as key-value pairs, not raw conversation logs
- **Semantic indexing**: Embeddings enable retrieval of relevant memory based on task similarity
- **Scoped per agent**: Memory doesn't leak across different agents (privacy and context isolation)
- **User-editable**: Users can view, modify, or delete stored memory (transparency and control)
- **Versioned updates**: Memory evolves incrementally as users provide more feedback

**What gets remembered:**
- **Corrections**: When users fix agent outputs ("use this column name, not that one")
- **Preferences**: Tone, format, approach preferences from user feedback
- **Successful patterns**: Workflows that worked well get prioritized
- **Domain knowledge**: User's context (codebase conventions, business logic, common tasks)
- **Failure patterns**: What didn't work, to avoid repeating mistakes

**How memory shapes agent behavior:**
The memory system operates at three layers:
1. **System context** (global): Always-on instructions that apply to all tasks
2. **Retrieved memory** (task-specific): Semantic search pulls relevant past feedback
3. **Immediate conversation** (session): Current task context and active feedback

When an agent receives a task:
1. Semantic search retrieves relevant memory (similar past tasks, corrections, preferences)
2. Memory injects into prompt as additional context
3. Agent applies learned patterns to current task
4. New feedback updates memory for future tasks

**The learning loop vs. prompt engineering:**
- **Prompt engineering** (static): Write instructions once, agent follows them forever
- **Memory system** (dynamic): Agent learns from every interaction, accumulates knowledge over time

Example progression:
- **First task**: Agent generates SQL query, user corrects column name
- **Second task**: Agent remembers correct column name, generates accurate query
- **Over time**: Agent learns user's query patterns, naming conventions, join logic, optimization preferences
- **Result**: Agent becomes personalized to user's codebase without manual prompt updates

**Technical challenges solved:**
- **Memory retrieval quality**: Embedding-based search finds relevant context without exact keyword match
- **Context window management**: Memory competes with task context; system prioritizes most relevant items
- **Memory staleness**: Outdated patterns need pruning when user behavior changes
- **Conflicting feedback**: When corrections contradict, system weights recent feedback higher

**Why it matters for PMs:**
This documents the production architecture for persistent agent memory—showing it's not just "remember conversation history" but structured knowledge that actively changes agent behavior. For PMs building agents with memory, the question becomes: how do you design feedback loops that teach useful patterns versus accumulating noise? LangChain's approach—semantic retrieval, user editability, and scoped storage—provides reference patterns.

**Critical questions:**
- Storage costs at scale: how much data per user, and what's retention policy?
- Quality degradation: when does accumulated memory create brittleness versus improving performance?
- Cross-agent memory: could memory be shared safely (e.g., team-level patterns)?
- Evaluation: how do you measure whether memory actually improves agent outputs?
- Privacy: where is memory stored, who can access it, and can users export it?

**Action you could take today:**
If you're building agents with memory, prototype the feedback loop explicitly: when a user corrects an agent, store that correction as structured data (JSON, database row) and retrieve it on similar tasks. Test whether applying stored corrections improves future outputs—or if memory just adds complexity without measurable gains. This calibrates whether memory is valuable for your use case.

---

### Vercel - 69,000+ Agent Skills & Video Generation on AI Gateway
**Source:** https://vercel.com/blog/skills-night-69000-ways-agents-are-getting-smarter
**Source:** https://vercel.com/blog/video-generation-with-ai-gateway
**Credibility:** High (first-party product launches with technical implementation)

**What happened:** Vercel launched two major infrastructure expansions: 69,000+ agent skills in their marketplace and video generation models (Grok Imagine Video, Wan, Kling, Veo) through AI Gateway. The pattern: agent infrastructure scaling to multimodal workflows and composable capabilities.

**69,000+ agent skills—what this means architecturally:**

**What "skills" are:**
- Pre-built tool integrations agents can invoke (APIs, databases, services, workflows)
- Composable capabilities—agents combine multiple skills per task
- Community-contributed beyond Vercel's core offerings
- Skills span: data processing, API integration, deployment automation, content generation, system administration

**The marketplace model:**
Instead of every team building custom agent tools, Vercel provides a skills registry. Agents discover and invoke skills dynamically based on task requirements. This shifts agent development from "build all tools from scratch" to "orchestrate existing skills."

**Example skill types:**
- **Data processing**: CSV parsing, JSON transformation, database queries
- **API integration**: GitHub operations, Slack notifications, email sending
- **Deployment**: Vercel deployment triggers, environment variable management
- **Content generation**: Image creation, video processing, text transformation
- **System tools**: File operations, command execution, network requests

**Why this matters vs. custom tooling:**
Building agent tools is expensive—each tool needs development, testing, maintenance. Skills marketplace commoditizes common patterns. The trade-off: less flexibility (use existing skills) versus faster development (skip building tools).

**Video generation models added:**

**Grok Imagine Video:**
- Text-to-video generation through xAI's model
- Multiple aspect ratios supported
- Streaming generation (progressive rendering as video generates)
- Cost-optimized for rapid iteration

**Wan models:**
- Chinese video generation models specialized for different styles
- Culturally-tuned outputs for Asian markets
- Cost-optimized pricing structure
- Integrated through unified API like text/image models

**Kling:**
- High-quality video synthesis with advanced motion control
- Longer duration support than competing models (up to 60 seconds)
- Focus on motion coherence and style consistency
- Quality/cost trade-off positioning for production use

**Veo (Google's model):**
- Experimental video generation through Google Cloud integration
- Early access through Vercel Gateway
- Emphasis on photorealistic rendering
- Preview-stage quality and pricing

**Why Gateway matters for video:**
Video generation poses different infrastructure challenges than text/image:
- **Latency**: Minutes to generate versus seconds for images
- **Cost**: Per-second video pricing varies 10-100x across providers
- **Quality variance**: Motion coherence, duration limits, resolution differ significantly
- **Storage/bandwidth**: Video outputs are large; caching and delivery matter
- **Progressive rendering**: Users need feedback during generation, not just final output

AI Gateway's unified API handles: model routing based on cost-quality trade-offs, automatic failover when providers are slow, and progressive delivery (stream partial results).

**The infrastructure convergence:**
Skills + video generation = multimodal agent infrastructure becoming production-ready. Agents now operate across:
- **Code execution** (Sandboxes from Jan 31)
- **API orchestration** (69,000+ skills)
- **Image generation** (Midjourney, DALL-E, Stable Diffusion)
- **Video generation** (Grok, Kling, Veo, Wan)

All through unified infrastructure layers—not separate integrations per capability.

**Why it matters for PMs:**
This continues the sandbox infrastructure pattern (Jan 31) and multi-model orchestration (Feb 7): agent infrastructure is modularizing. For PMs building agents, the build-vs-buy calculus shifts: instead of "should we support video generation?" the question becomes "which video models through which infrastructure?" The 69,000 skills marketplace also signals: agents are moving from custom implementations to composable capabilities. The risk: over-reliance on marketplace skills creates vendor lock-in. The opportunity: accelerate development by leveraging existing tooling.

**Critical questions:**
- Cost structure for video generation at scale: what's per-video cost across models?
- Latency distribution: how long does typical video generation take (p50, p95, p99)?
- Quality comparison: which models excel for which use cases (product demos vs. artistic content)?
- Skills marketplace quality: how do teams validate community-contributed skills before deploying?
- Storage implications: where do generated videos live, who pays for bandwidth, what's retention policy?

**Action you could take today:**
If you're building features that might need video (product demos, content creation, visualization), prototype video generation through one workflow. Test Grok Imagine Video or Kling with the same prompt at different durations. Measure: cost, latency, quality, and whether Gateway's abstraction layer actually simplifies orchestration versus calling models directly. This calibrates whether video generation is feasible for your use case—or still too expensive/slow for production.

---

### LangChain - Agent Observability Powers Agent Evaluation
**Source:** https://blog.langchain.com/agent-observability-powers-agent-evaluation/
**Credibility:** High (detailed technical architecture with evaluation framework)

**What happened:** LangChain published their approach to agent evaluation—arguing that observability isn't just debugging infrastructure, it's the foundation for systematic evaluation and improvement.

**Key evaluation patterns:**

**Why observability enables evaluation:**
Traditional evaluation: run agent on test cases, check if outputs match expected results. This misses:
- **Why did the agent succeed or fail?** Which reasoning steps broke?
- **What tools were invoked?** Did agent use optimal tool chain?
- **Where did latency spike?** Which steps consumed time?
- **How much did it cost?** Which model calls were expensive?

Observability captures these signals automatically through tracing and logging. Evaluation then analyzes traces to understand agent behavior, not just outputs.

**The evaluation workflow:**
1. **Capture traces**: LangSmith logs every agent step (model calls, tool invocations, reasoning)
2. **Define success criteria**: What makes a "good" agent response? (accuracy, speed, cost, tool efficiency)
3. **Analyze traces**: Compare successful vs. failed runs—what patterns differ?
4. **Identify improvements**: Where did reasoning break? Which tools were misused? What context was missing?
5. **Iterate and re-evaluate**: Change agent logic, re-run evaluation, measure improvement

**Example evaluation scenario—coding agent:**
- **Task**: "Fix the bug in this function"
- **Successful run**: Agent reads code → identifies bug → writes fix → runs tests → succeeds
- **Failed run**: Agent reads code → guesses wrong bug → writes incorrect fix → tests fail → gives up
- **Trace analysis reveals**: Failed run didn't execute tests before proposing fix (skipped verification step)
- **Improvement**: Add "run tests to validate hypothesis" step to reasoning

**What gets evaluated through observability:**
- **Reasoning quality**: Did agent decompose task correctly? Were intermediate steps logical?
- **Tool selection**: Did agent choose optimal tools? Were retries necessary?
- **Context usage**: Did agent retrieve relevant context? Was information correctly applied?
- **Error recovery**: When failures occurred, did agent adapt or repeat mistakes?
- **Resource efficiency**: Were model calls necessary? Could cheaper models have worked?

**Why it matters for PMs:**
This connects observability infrastructure (LangSmith from Feb 10) to product improvement workflows. For PMs building agents, the question shifts from "is my agent working?" to "why is my agent working—and how do I make it work better?" Evaluation becomes continuous process, not one-time testing. The implication: observability isn't optional infrastructure—it's required for systematic agent improvement.

**Critical questions:**
- How much trace data do you need before evaluation is statistically meaningful?
- Does evaluation catch systematic biases in agent reasoning, or just obvious failures?
- What's the latency overhead of comprehensive tracing in production?
- Can you evaluate agents without observability—or is it fundamentally required?

**Action you could take today:**
If you're building agents, implement basic evaluation: run your agent on 10 test tasks, capture traces, and manually analyze one successful and one failed run. Ask: what reasoning steps differed? Which tools were used differently? What context was present or missing? This calibrates whether trace analysis actually reveals actionable improvements—or if it's just interesting data.

---

## Quick Hits

- **Teresa Torres**: [Building AI Sales Reps: ShowMe case study](https://www.producttalk.org/building-ai-sales-reps-showme/) - Detailed architecture for multimodal agents handling voice, video, and screen sharing (Feb 19)
- **Lenny Rachitsky**: [Head of Claude Code interview](https://www.lennysnewsletter.com/p/head-of-claude-code-what-happens) - Discussion of what happens when coding is "solved" (Feb 19)
- **Microsoft/GitHub**: [How AI reshapes developer choice](https://github.blog/ai-and-ml/generative-ai/how-ai-is-reshaping-developer-choice-and-octoverse-data-proves-it/) - Octoverse data on AI developer adoption patterns (Feb 19)
- **Replicate**: [Recraft V4 for image generation](https://replicate.com/blog/recraft-v4) - Design-focused image generation with SVG support and strong composition (Feb 18)
- **Microsoft/GitHub**: [Agentic Workflows launch](https://github.blog/ai-and-ml/automate-repository-tasks-with-github-agentic-workflows/) - Automate repository tasks in CI/CD pipelines (Feb 13, detailed in Feb 14 update)

---

## This Week's Pattern

**Memory and multimodal infrastructure as production requirements.** LangChain reveals production architecture for agent memory—structured feedback stored with semantic indexing that actively shapes future behavior. Vercel ships 69,000+ skills and video generation through AI Gateway—expanding agent infrastructure to composable capabilities and multimodal workflows. The convergence: agents becoming persistent, learning systems that operate across text, images, video, and code—requiring memory systems and orchestration infrastructure beyond raw model APIs.

---

## Reflection Prompt

LangChain's memory system stores user corrections as structured, semantically-indexed feedback that agents actively apply to future tasks—making agents that improve through usage rather than static prompt engineering.

**For your agent product:** What would your agent remember if it could learn from every user interaction? Which corrections or preferences should persist across sessions? How would you design feedback loops that actually teach useful patterns—versus accumulating noise or encoding user mistakes? And what's the switching cost when users invest weeks training an agent to their specific workflow and domain knowledge?

Complete your reflection in `/content/reflections/daily/2026-02-22.md`