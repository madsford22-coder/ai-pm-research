---
title: "LangSmith Agent Builder GA & Google Vertex AI Agent Pricing"
date: 2026-01-26
tags:
  - daily-update
  - ai-pm-research
---

# Daily PM Research Update: 2026-01-26

## One-Line Summary

LangSmith Agent Builder reaches general availability with no-code agent creation, while Google announces pricing changes for Vertex AI Agent Engine—both signaling the agent-as-product era moving from experimentation to production economics.

---

## Items

### LangChain - LangSmith Agent Builder Now Generally Available
**Source:** https://www.blog.langchain.com/langsmith-agent-builder-generally-available/
**Credibility:** High (first-party GA announcement, available across all LangSmith tiers)

**What happened:** LangSmith Agent Builder reached general availability—a no-code platform for creating AI agents that handle complex, routine tasks. The framing: "An agent should feel like your chief of staff: you share what you need, it figures out how to get it done."

**Key capabilities now GA:**

- **Natural language setup**: Describe goals conversationally; system determines optimal approach
- **Intelligent tool selection**: Builder automatically identifies and configures necessary tools
- **Subagent deployment**: Creates subordinate agents when needed for complex tasks
- **Learning from feedback**: Agents improve through user corrections, "functioning like collaborative team members"
- **Permission-based execution**: Can request approval before sensitive actions

**Real-world use cases already in production:**
- Generating personalized meeting briefs with research and CRM context
- Delivering daily market intelligence and competitor updates
- Converting product requirements into project management tickets

**Extensibility:**
- Connect additional tools via MCP servers
- Select different AI models per agent
- Embed agents in products or invoke via API

**Why it matters for PMs:**
This is the "Webflow for agents" moment—moving from code-required to no-code. The permission-based execution model is notable: it addresses the trust problem by letting agents ask before acting. For PMs evaluating build-vs-buy for agent capabilities, the question shifts from "can we build an agent?" to "should we build custom vs. use a platform?"

**Critical questions:**
- What's the ceiling on complexity before no-code tools force you back to code?
- "Learning from feedback" implies state persistence—how is that data governed?
- Available across all LangSmith tiers—but what are the actual usage limits per tier?

**Action you could take today:**
Identify one recurring PM task that fits the "chief of staff" pattern—meeting prep, competitive intel, ticket creation. Try building it in Agent Builder. The goal isn't production deployment; it's calibrating what no-code agents can actually do.

---

### Google - Vertex AI Agent Engine Pricing Changes
**Source:** https://cloud.google.com/vertex-ai/pricing#vertex-ai-agent-engine
**Credibility:** High (first-party pricing announcement, effective January 28)

**What happened:** Google announced pricing changes for Vertex AI Agent Engine Runtime. Runtime pricing was lowered, but Sessions, Memory Bank, and Code Execution will begin charging for usage starting January 28, 2026.

**What this signals:**
- **Runtime costs decreasing**: Base compute for running agents is getting cheaper
- **Feature-based pricing emerging**: Sessions (conversation state), Memory Bank (persistent memory), and Code Execution (sandboxed code) become paid features
- **Agent infrastructure maturing**: Moving from "try it free" to production pricing models

**Why it matters for PMs:**
Agent pricing models are stabilizing around feature tiers: base runtime is cheap, but state management (sessions, memory) and execution capabilities (code) cost extra. For PMs budgeting AI agent features, this suggests a cost model: simple stateless agents are cheap; agents that remember context or execute code cost more.

**Critical questions:**
- What's the per-session and per-memory-operation pricing? (Not disclosed in announcement)
- How does this compare to building your own state management vs. using their Memory Bank?
- Does code execution pricing make sandboxed execution prohibitively expensive for high-volume use cases?

**Action you could take today:**
If you're using Vertex AI agents, audit your session and memory usage before January 28. Estimate what the new pricing will cost. If memory/sessions are expensive, consider whether you can architect around them.

---

## Quick Hits

- **LangChain**: [Introducing Agent Builder templates](https://www.blog.langchain.com/introducing-agent-builder-template-library/) - 7 ready-to-deploy templates for Calendar Brief, Email Assistant, Incident Responder, and more (Jan 24, covered in detail Jan 21)
- **Vercel**: [Configure build machine settings across all projects](https://vercel.com/changelog) - Teams can now apply build configs (Standard/Enhanced/Turbo) across all projects simultaneously (Jan 23)
- **Vercel**: [Faster deploys with improved function caching](https://vercel.com/changelog) - Function uploads skip when code unchanged, reducing build times 400-600ms (Jan 23)
- **Google**: [GLM 4.7 GA in Model Garden](https://cloud.google.com/vertex-ai/docs/release-notes) - Designed for coding, tool use, and complex reasoning (Jan 20)

---

## This Week's Pattern

**Agents moving from experimentation to production economics.** LangSmith Agent Builder goes GA with no-code creation. Google introduces usage-based pricing for agent features. The shift: agent infrastructure is maturing from "can we build it?" to "how do we price it?" and "how do we make it accessible?"

---

## Reflection Prompt

LangSmith frames Agent Builder as creating a "chief of staff"—you share what you need, it figures out how to get it done.

**For your PM practice:** What recurring tasks would benefit from a "chief of staff" pattern—where you describe the goal and delegate the execution? What would you trust an agent to do autonomously vs. where would you want approval gates?

Complete your reflection in `/content/reflections/daily/2026-01-26.md`
