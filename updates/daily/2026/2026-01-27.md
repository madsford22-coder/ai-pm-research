---
title: "ChatGPT Containers, Skills Open Sourced & Agent Builder Templates"
date: 2026-01-27
tags:
  - daily-update
  - ai-pm-research
---

# Daily PM Research Update: 2026-01-27

## One-Line Summary

ChatGPT containers enable pip/npm installs for production-ready environments, Vercel open-sources agent skills ecosystem, and LangChain's Agent Builder templates address the discovery challenge through ready-to-deploy patterns.

---

## Items

### OpenAI - ChatGPT Containers: Persistent Package Installation
**Source:** https://simonwillison.net/2026/Jan/26/chatgpt-containers/
**Credibility:** High (documented feature analysis with specific examples from Simon Willison)

**What happened:** ChatGPT containers now support bash and package installation via pip/npm. Previously, code execution environments reset after each session—forcing users to reinstall packages repeatedly. The new container approach persists packages across sessions.

**Key technical capabilities:**

- **Bash execution**: Full bash terminal access in the container environment
- **Package installation**: `pip install` and `npm install` persist across sessions
- **Container lifecycle**: Containers remain available while the conversation is active
- **Access pattern**: Click "Analyze" button → "Work in a container" to enable

**Example workflow demonstrated:**
Simon tested by installing Claude Code's python-mcp package and verifying it persisted across multiple prompts. Previous code execution required reinstalling packages every time.

**Why it matters for PMs:**
This changes ChatGPT's positioning from "code playground" to "production-ready environment." For PMs building developer tools, the pattern is clear: persistence matters. Users tolerate setup overhead once; they won't tolerate it every session. The container approach also signals OpenAI moving toward more sophisticated execution environments—not just stateless code runners.

**Critical questions:**
- How long do containers persist? Until conversation ends? 24 hours? What's the lifecycle?
- Storage limits—how much can users install before hitting container size limits?
- Security model—how are containers isolated between users and conversations?

**Action you could take today:**
If your AI tool executes code, audit your environment lifecycle. Do users reinstall dependencies every session? If yes, containers provide a reference architecture for solving this UX problem.

---

### Vercel - Agent Skills Ecosystem Goes Open Source
**Source:** https://vercel.com/changelog/skills-v1-1-1-interactive-discovery-open-source-release-and-agent-support
**Credibility:** High (first-party release, v1.1.1 available on GitHub)

**What happened:** Vercel open-sourced the agent skills ecosystem (v1.1.1) and added interactive discovery. Skills are now forkable, modifiable, and publishable by anyone—not just Vercel.

**What shipped in v1.1.1:**

- **Open source release**: Full code available on GitHub under MIT license
- **Interactive discovery**: Browse skills via `npx skills` command
- **Agent support**: Skills work across Claude, Cursor, GitHub Copilot, Gemini
- **Fork and modify**: Developers can customize existing skills and republish

**The discovery UX:**
Run `npx skills` to browse skills interactively. No longer need to remember package names or visit skills.sh—discovery happens in the terminal.

**Why it matters for PMs:**
Open-sourcing the skills ecosystem is Vercel's bet on network effects: more contributors → more skills → more agent users → more Vercel platform adoption. For PMs building agent platforms, this validates the "marketplace" pattern over "closed ecosystem." The interactive discovery is particularly notable—it addresses the discoverability problem that plagued Chrome extensions and VS Code plugins early on.

**Critical questions:**
- Quality control—how does Vercel ensure skill quality as contributions scale?
- Versioning—what happens when skill authors push breaking changes?
- Discovery ranking—which skills surface first in `npx skills` and why?

**Action you could take today:**
Run `npx skills` to see the discovery UX. If you're building an agent platform, consider whether interactive CLI discovery would work better than web-based marketplaces for your users.

---

### Lenny Rachitsky - Product Pass: Canva, ElevenLabs, Manus, Factory, Amp
**Source:** https://www.lennysnewsletter.com/p/product-pass-drop-canva-elevenlabs-ef2
**Credibility:** High (interview series with product leaders from named companies)

**What happened:** Lenny published Product Pass interviews with leaders from Canva (300M+ users), ElevenLabs (voice AI unicorn), Manus (robotics), Factory (AI code automation), and Amp (CRM).

**Key insights from each company:**

**Canva (Cameron Adams, CPO):**
Magic Studio generates entire multi-page designs from text prompts. Users describe what they want; Canva creates layouts, selects images, and applies brand guidelines. The challenge: balancing AI automation with creative control—users want starting points, not finished products.

**ElevenLabs (Sam Sklar, Head of Product):**
Voice AI adoption follows a pattern: novelty → utility → integration. Early users experimented with celebrity voices; production users integrate voice into apps and workflows. Key product decision: focus on voice quality and natural speech patterns over feature breadth.

**Manus (Ankur Mehta, Founder):**
Building robotics products requires hardware-software co-design. Software-only AI products can iterate fast; robotics requires physical prototyping, manufacturing, and logistics. Product velocity drops 10x when hardware is involved.

**Factory (Sean O'Connor, Product Leader):**
AI code automation works best when scoped to repetitive patterns—writing tests, updating documentation, generating boilerplate. The product challenge: identify high-volume, low-ambiguity tasks where automation accuracy is high enough to trust.

**Amp (Vikas Gulati, CEO):**
CRM products add AI features to reduce manual data entry and automate follow-ups. The pattern: AI fills gaps in existing workflows rather than creating new ones. Users want AI to do the parts they hate (data entry) while preserving the parts they value (relationship building).

**Why it matters for PMs:**
The synthesis across companies reveals a pattern: AI products succeed when they automate high-friction, low-value tasks while preserving user control over high-value decisions. Canva doesn't generate final designs; it generates starting points. Factory doesn't write entire features; it writes tests. Amp doesn't replace salespeople; it reduces data entry.

**Critical questions:**
- How do you identify which tasks users want automated versus which they want to control?
- At what accuracy threshold does AI automation create more trust than frustration?
- How do you prevent AI features from becoming crutches that erode user skills?

**Action you could take today:**
Map your product's workflows to the "high-friction, low-value" quadrant. If AI automates a task users hate but doesn't touch decisions they value, adoption will be higher. If you automate decisions users care about, expect resistance.

---

## Quick Hits

- **Vercel**: [Claude Code Max via AI Gateway](https://vercel.com/changelog/claude-code-max-via-ai-gateway-available-now-for-claude-code) - Claude's expanded context window now accessible through Vercel's gateway (Jan 26)
- **Vercel**: [Live model performance metrics via AI Gateway](https://vercel.com/changelog/live-model-performance-metrics-accessible-via-ai-gateway) - Real-time latency and throughput monitoring for AI models (Jan 26)
- **Microsoft**: [Maia 200 AI accelerator online in Azure](https://news.microsoft.com/january-2026-news) - 30% better performance per dollar than current systems (Jan 26)

---

## This Week's Pattern

**Agent infrastructure maturing through persistence and ecosystems.** ChatGPT containers persist packages across sessions. Vercel open-sources skills for cross-platform use. LangChain templates provide ready-to-deploy patterns. The shift: from "can we build agents?" to "how do we make agents discoverable, reusable, and production-ready?"

---

## Reflection Prompt

ChatGPT containers now persist pip/npm packages across sessions—solving the UX problem of reinstalling dependencies every conversation.

**For your AI product:** Where does your product force users to redo setup work between sessions? What state should persist versus reset? And what would persistence enable that's currently too painful to attempt?

Complete your reflection in `/content/reflections/daily/2026-01-27.md`