---
title: "Building AI Product Sense & Maximizing Copilot's Agentic Capabilities"
date: 2026-02-03
tags:
  - daily-update
  - ai-pm-research
---

# Daily PM Research Update: 2026-02-03

## One-Line Summary

Lenny reveals how PMs build AI product sense through deliberate practice and pattern recognition, while GitHub demonstrates advanced agentic techniques that transform Copilot from code assistant to autonomous workflow orchestrator.

---

## Items

### Lenny Rachitsky - How to Build AI Product Sense: Pattern Recognition & Deliberate Practice
**Source:** https://www.lennysnewsletter.com/p/how-to-build-ai-product-sense
**Credibility:** High (detailed framework with specific practices and examples)

**What happened:** Lenny published a comprehensive guide on developing AI product sense—the ability to make good product decisions in AI contexts. The core insight: AI product sense is trainable through deliberate practice, not just experience accumulation.

**Key skill-building patterns:**

**1. Active experimentation over passive consumption:**
Use AI products daily, but critically. Don't just accept outputs—examine why they work or fail. Try breaking them. Push edge cases. The pattern: hands-on experimentation builds intuition faster than reading about products.

**2. Pattern recognition across domains:**
Study how different AI products solve similar problems. Example: how do ChatGPT, Perplexity, and Notion AI handle context management differently? Comparing approaches reveals design choices and tradeoffs.

**3. Understand one layer deeper than you think you need:**
You don't need to be an ML engineer, but understanding tokenization, context windows, and embeddings reveals why certain product decisions matter. Example: knowing context limits explains why agents spawn subagents.

**4. Build taste through volume:**
Ship small AI features rapidly. Volume builds judgment. Lenny emphasizes: "You can't develop product sense without shipping." Each launch teaches what works versus what sounded good in planning.

**5. Learn from post-mortems (yours and others'):**
Study why AI features succeed or fail. Teresa Torres' Healio case study (Jan 22) is an example: physicians wanted AI for empathy, not diagnostics. Wrong assumptions = wrong product.

**The meta-skill: connecting technical constraints to user value:**
Strong AI product sense means knowing when technical limitations (latency, cost, accuracy) justify UX tradeoffs versus when they're deal-breakers.

**Why it matters for PMs:**
This addresses a skill gap many PMs face: how do I get better at AI products when the field changes weekly? The framework is actionable: use products daily, compare patterns, ship small experiments, study failures. Unlike general "build product sense" advice, this is specific to AI's unique constraints.

**Critical questions:**
- How do you balance deliberate practice with actual product delivery when time is limited?
- At what point does understanding technical details become over-indexing versus essential?
- Which patterns are universal versus specific to current model capabilities?

**Action you could take today:**
Pick one AI product you use weekly. For the next week, deliberately break it—push edge cases, test limits, observe failures. Document what you learn about its architecture, quality bars, and design choices. This is pattern recognition practice.

---

### Microsoft/GitHub - Maximizing GitHub Copilot's Agentic Capabilities
**Source:** https://github.blog/ai-and-ml/github-copilot/how-to-maximize-github-copilots-agentic-capabilities/
**Credibility:** High (first-party technical guide with concrete workflows)

**What happened:** GitHub published advanced techniques for using Copilot's agentic capabilities—moving beyond autocomplete to autonomous task execution. The guide demonstrates multi-step workflows, context management, and tool orchestration.

**Key agentic patterns demonstrated:**

**Multi-step task planning:**
- Agent breaks down complex requests into discrete steps
- Plans execution order based on dependencies
- Handles errors by replanning versus halting

**Context-aware tool selection:**
- Agent automatically chooses appropriate tools (bash, file editing, API calls)
- Switches tools mid-workflow when initial approach fails
- Uses project structure and language context to optimize tool choice

**Iterative refinement loops:**
- Agent runs code, observes output, adjusts approach
- Example: generate test → run test → fix failures → verify → commit
- Human approval gates at critical decision points

**Example workflow—"Set up Python project with testing":**
1. Agent creates virtualenv
2. Installs dependencies from requirements.txt
3. Configures pytest
4. Generates initial test structure
5. Runs tests to verify setup
6. Commits if successful, fixes if not

**Why agentic vs. autocomplete matters:**
Autocomplete assists; agents execute. The distinction: autocomplete requires you to drive the workflow; agents drive the workflow with your oversight. This changes PM productivity potential—delegating entire tasks versus completing individual steps faster.

**Why it matters for PMs:**
This continues the pattern from Jan 26-29 updates: AI moving from "answer questions" to "do the work." For PMs who code (prototyping, data analysis, internal tools), agentic workflows shift the question from "how do I write this?" to "what should this accomplish?" The productivity gain isn't linear—it's a phase shift in what you can delegate.

**Critical questions:**
- At what error rate does delegation create more overhead (reviewing agent actions) than value?
- How do you build trust in agent execution when stakes are high (production code, customer data)?
- What's the learning curve from "use autocomplete" to "orchestrate agents"?

**Action you could take today:**
Next time you have a multi-step development task (set up project, run migrations, update dependencies), try delegating the entire workflow to Copilot CLI versus doing each step manually. Observe where the agent succeeds versus where you intervene. This calibrates realistic delegation boundaries.

---

## Quick Hits

- **Vercel**: [Python 3.13 and 3.14 now available](https://vercel.com/changelog/python-3-13-and-3-14-are-now-available) - Latest Python runtimes supported (Feb 2)
- **GitHub**: [7 learnings from Anders Hejlsberg](https://github.blog/developer-skills/programming-languages-and-frameworks/7-learnings-from-anders-hejlsberg-the-architect-behind-c-and-typescript/) - C# and TypeScript architect shares design insights (Jan 27)

---

## This Week's Pattern

**AI product sense as deliberate practice.** Lenny frames skill-building through active experimentation and pattern recognition across products. GitHub demonstrates advanced agentic techniques that require understanding one layer deeper than autocomplete. The shift: AI product sense isn't accidental—it's trainable through specific practices.

---

## Reflection Prompt

Lenny argues AI product sense develops through deliberate practice: use products daily, compare patterns across domains, understand one layer deeper than necessary, ship rapidly, and study failures.

**For your AI learning:** Which of these practices are you actually doing versus intending to do? Pick one—active experimentation, pattern comparison, or post-mortem analysis—and commit to practicing it daily for the next week. What would that look like concretely?

Complete your reflection in `/content/reflections/daily/2026-02-03.md`