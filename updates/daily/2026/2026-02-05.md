---
title: "How Perplexity Doubled Deep Search Speed & Earmark's Meeting Automation"
date: 2026-02-05
tags:
  - daily-update
  - ai-pm-research
---

# Daily PM Research Update: 2026-02-05

## One-Line Summary

Perplexity's Advanced Deep Research ships with 2x faster multi-step reasoning, Teresa reveals how Earmark's two-person team automated meeting workflows without losing human judgment, and Marty Cagan argues AI won't replace product coaches—but will change how they work.

---

## Items

### Perplexity - Advanced Deep Research: Faster Multi-Step Reasoning
**Source:** https://x.com/AravSrinivas/status/2019129261584752909
**Credibility:** High (CEO announcement with product launch)

**What happened:** Aravind Srinivas announced Advanced Deep Research—a 2x speed improvement for Perplexity's multi-step research agent. The upgrade maintains answer quality while reducing latency from minutes to sub-minute response times for complex queries.

**Key technical improvements:**

**Latency reduction patterns:**
- **Model optimization**: Switched to faster reasoning models without sacrificing depth
- **Parallel execution**: Research steps that don't depend on each other now run simultaneously
- **Smarter routing**: Simpler sub-questions use lighter models; complex ones use expensive models
- **Progressive disclosure**: Partial results stream while later steps execute

**What stays the same:**
- Multi-step research workflow (decompose → research → synthesize)
- Citation quality and source transparency
- Number of sources consulted per query

**Why speed matters here:**
Deep research competes with manual research—users open multiple tabs, scan articles, synthesize findings. If the agent takes 5 minutes, users switch to manual. If it takes 90 seconds, the tradeoff shifts. Speed isn't just UX—it changes whether the product substitutes manual work or complements it.

**Why it matters for PMs:**
This continues the Jan 30-Feb 4 pattern: agents moving from "can it work?" to "can it work fast enough to replace manual workflows?" Perplexity's bet is that latency—not capability—is the adoption barrier. For PMs building agents, the question becomes: at what latency does your agent cross the threshold from "interesting demo" to "replaces manual work"?

**Critical questions:**
- What's the accuracy delta between Advanced and standard Deep Research?
- Does 2x speed come from model improvements (which all products can adopt) or architectural optimizations (which are defensible)?
- How much does parallelization help versus just using faster models?

**Action you could take today:**
If you're building multi-step agents, measure your users' tolerance for latency. Run tests: does 90 seconds feel acceptable? 3 minutes? Find the threshold where users switch to manual work, then architect to stay under it.

---

### Teresa Torres - Building Earmark: Meeting Automation Without Losing Judgment
**Source:** https://www.producttalk.org/building-earmark-how-a-two-person-team-turned-meetings-into-finished-work/
**Credibility:** High (detailed case study with specific product decisions)

**What happened:** Product Talk published a case study on Earmark—a two-person team building AI-powered meeting automation. The core insight: they automate transcription and drafting but preserve human judgment for decisions.

**Key product patterns:**

**Where AI takes over:**
- **Real-time transcription**: Live transcripts during meetings (accuracy: 95%+)
- **Draft generation**: AI generates action items, summaries, and follow-ups from transcripts
- **Context extraction**: Pulls relevant information (decisions, blockers, commitments) automatically

**Where humans remain essential:**
- **Editing drafts**: AI generates; humans refine before sending
- **Decision validation**: AI flags decisions; humans confirm accuracy
- **Relationship management**: AI drafts follow-ups; humans personalize tone and context

**The two-person advantage:**
Building with a tiny team forces ruthless prioritization. They focused on one workflow (meeting → finished work) rather than building a full meeting platform. The constraint became a feature—deep execution on a narrow problem.

**Technical architecture:**
- **Speech-to-text API**: Off-the-shelf (Deepgram or similar)
- **LLM for drafting**: OpenAI/Anthropic for generating summaries and action items
- **Human-in-the-loop UX**: Draft → edit → approve workflow with clear approval gates

**Why it matters for PMs:**
This validates the "automate execution, preserve judgment" pattern from previous updates (Healio, v0, Sensay). Earmark doesn't try to replace the human—it handles the low-value parts (transcription, initial drafts) while humans do high-value work (editing, relationship management). For PMs scoping AI features, the question is: which parts of the workflow are high-volume but low-judgment?

**Critical questions:**
- What's the error rate on action item extraction, and how does that affect trust?
- Two-person team means limited surface area—how do they prioritize new features versus deepening the core workflow?
- Does this pattern scale to other meeting types (sales, customer calls, 1:1s)?

**Action you could take today:**
Map one recurring workflow (meetings, emails, research) to the "automate execution, preserve judgment" pattern. Identify which steps are high-volume but low-ambiguity (transcription, drafting) versus which require human judgment (editing, decision validation). Prototype automating the former while keeping humans in control of the latter.

---

### Marty Cagan - Product Coaching and AI: Augmentation, Not Replacement
**Source:** https://www.svpg.com/product-coaching-and-ai/
**Credibility:** High (detailed analysis from product management thought leader)

**What happened:** Marty Cagan published his perspective on how AI will affect product coaching—arguing that while AI can augment coaches, it won't replace the core coaching relationship.

**Key insights on AI's role in coaching:**

**Where AI helps coaches:**
- **Preparation**: AI analyzes team artifacts (PRDs, user research, roadmaps) before coaching sessions
- **Pattern recognition**: AI surfaces patterns across teams (common mistakes, recurring blockers)
- **Knowledge synthesis**: AI compiles relevant frameworks, case studies, and best practices for specific coaching contexts
- **Documentation**: AI generates session summaries and action items

**Where AI can't replace coaches:**
- **Trust building**: Coaching requires psychological safety—humans build trust, AI can't
- **Context reading**: Coaches read body language, tone, and team dynamics that AI misses
- **Tailored advice**: Effective coaching adapts to individual learning styles and team culture
- **Accountability**: Humans hold each other accountable; AI reminders don't carry the same weight

**The augmentation model:**
Coaches use AI for research, preparation, and administrative work—freeing time for high-value human interactions. The AI handles "what does SVPG say about discovery?" The coach handles "given your team's culture and context, here's how to apply it."

**Why it matters for PMs:**
This frames a broader pattern: AI augments expert judgment rather than replacing it. The same logic applies to PMs—AI can draft PRDs, analyze data, and generate options. But PMs make the call on strategy, navigate stakeholder dynamics, and build team trust. For PMs evaluating AI tools, the question is: does this tool handle execution work so I can focus on judgment?

**Critical questions:**
- How much preparation time does AI actually save coaches versus just adding a new tool to manage?
- What happens when teams over-rely on AI-generated coaching advice without human interpretation?
- Does AI coaching work for junior PMs learning fundamentals versus senior PMs refining judgment?

**Action you could take today:**
If you work with coaches (product coaches, engineering leaders, exec coaches), ask them: what parts of their work are high-volume preparation versus high-value interaction? Explore whether AI could handle the preparation, freeing them to focus on the human interaction.

---

## Quick Hits

- **Vercel**: [Content negotiation for agent-friendly pages](https://vercel.com/blog/making-agent-friendly-pages-with-content-negotiation) - Serve structured data to agents, HTML to browsers (Feb 3, detailed Feb 4)
- **Microsoft**: [Agent HQ now supports Claude and Codex](https://github.blog/news-insights/company-news/pick-your-agent-use-claude-and-codex-on-agent-hq/) - Multi-model agent platform (Feb 4)
- **Vercel**: [Parallel joins Agent Marketplace](https://vercel.com/changelog/parallel-joins-the-vercel-agent-marketplace) - Web search and tools available (Feb 4)

---

## This Week's Pattern

**Speed as adoption threshold.** Perplexity doubles Deep Research speed because latency—not capability—blocks manual workflow replacement. Earmark automates transcription and drafting fast enough that humans can focus on judgment. The shift: agents cross from "interesting" to "useful" when they're fast enough to substitute manual work, not just augment it.

---

## Reflection Prompt

Marty Cagan argues AI can't replace product coaches because coaching requires trust, context reading, and tailored advice—all fundamentally human.

**For your PM work:** Where does AI augment your judgment versus where does it try to replace it? And when tools claim to "coach" or "advise," are they actually providing judgment—or just retrieving information that still requires your interpretation?

Complete your reflection in `/content/reflections/daily/2026-02-05.md`