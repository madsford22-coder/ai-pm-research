---
title: "When to Remove Features vs. Add Them - Daily Reflection"
date: 2025-12-30
tags:
  - reflection
  - pm-insights
  - product-strategy
  - feature-removal
summary: "Reflection on Vercel's decision to remove 80% of agent tools, exploring when feature removal improves reliability and product-market fit more than feature addition."
---

# Daily Product Reflection: 2025-12-30

## Product-Relevant Insight

Vercel removing 80% of their agent tools is a reminder that reliability often scales through subtraction, not addition. For an AI product, the decision to remove features comes down to whether they increase confidence, clarity, and repeatable value for users more than they expand surface area.

## My Judgment

**changes my thinking**

I've been focused on feature expansion as a path to product-market fit, but this signals that aggressive pruning is equally important. System-level evaluations matter because they give us an objective source of truth—our north star is product-market fit, and reaching it requires rapid iteration with clean practices that allow us to measure impact, isolate variables, and pull a kill switch quickly when something isn't working.

## The Implication for My Product Work

As systems scale, clean, modular tooling becomes essential. Without it, experimentation slows, failures compound, and reliability degrades. There's an inherent tension between holding a strong product vision and staying flexible—we need a point of view about what the product should become, while remaining honest if 90% of user value is concentrated in a single tool or workflow. Feature removal becomes a signal of learning, not failure. The hardest part is identifying which feature gets us to PMF, which usually requires a period of breadth before depth: explore, observe where real value accrues, and then aggressively prune.

## One Open Question

How do you distinguish between features that are early-stage experiments worth keeping versus features that are actively degrading reliability and should be killed?

- [x] Reflection complete

---

## Full Reflection

Vercel removing 80% of their agent tools is a reminder that reliability often scales through subtraction, not addition.

For an AI product, the decision to remove features comes down to whether they increase confidence, clarity, and repeatable value for users more than they expand surface area. As systems scale, clean, modular tooling becomes essential. Without it, experimentation slows, failures compound, and reliability degrades.

System-level evaluations matter here because they give us an objective source of truth. Our north star is product–market fit, and reaching it requires rapid iteration. That means building with clean practices that allow us to measure impact, isolate variables, and pull a kill switch quickly when something isn't working.

There's an inherent tension between holding a strong product vision and staying flexible. We need a point of view about what the product should become, while remaining honest if 90% of user value is concentrated in a single tool or workflow. Feature removal becomes a signal of learning, not failure.

The hardest part is identifying which feature gets us to PMF. That usually requires a period of breadth before depth. We explore, observe where real value accrues, and then aggressively prune. Killing tools is not a retreat. It's how focus, reliability, and momentum emerge.

